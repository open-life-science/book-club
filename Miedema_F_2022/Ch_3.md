# Science in Transition: How Science Goes Wrong and What to Do About It

**Section §3.1. is unclear about what the "serious fraud cases" (p.68) Miedema has in mind entailed. The Schön Scandal seems decently explained [on Wikipedia](https://en.wikipedia.org/wiki/Schön_scandal), and Verfaeille & McGwin ([2011](https://www.apa.org/science/about/psa/2011/12/diederik-stapel)) explain the case surrounding Diederik Stapel in English. What other research scandals are you aware of? (I really like the work [Retraction Watch](https://retractionwatch.com) do on this front.)**

**§3.2. and §3.4. both mentioned the influence of funders on the design of research questions. Is this a topic that you have thought about, and why might it be worrying?**

**In §3.5., Miedema outlines some concerns relating with the proliferation of impact factors and other key performance indicators on the quality of research. I think it is worth celebrating some of the parody KPIs that have recently emerged. For example, the k-index (https://en.wikipedia.org/wiki/Kardashian_Index). Do you have any other examples of parody metrics that demonstrate what little value "serious" indicators have?**

**Page 88 mentions the sort of “excellence” that became linked to scientific work as performance indicators gained traction. “Elitism” is also used on page 89. Are these terms that you would use when describing academic work, or what it takes to succeed in academia? Why or why not?**

**§3.9. speaks of “physics envy”. Assuming you are aware of what has been called the [replication crisis](https://en.wikipedia.org/wiki/Replication_crisis), do you think that this is partly in response to the much more quantitative and experimentally evidenced nature of physics? In other words, is seeking reproducible experiments about the human mind motivated by the belief that science should progress like (some naive form of) physics? (I say “some naive form“ because physics encounters numerous issues at the quantum level; regarding causality and probability, for example.)**
